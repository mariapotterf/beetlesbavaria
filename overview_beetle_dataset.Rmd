---
title: "Beetle Data LWF Report"
author: "Maria Potterf"
date: "2024-12-13"
output: 
  html_document:
    toc: true           # Adds a table of contents
    toc_depth: 3        # Limits TOC to headings level 1 and 2
    number_sections: true  # Adds numbering to the headings
    toc_float: true     # Makes the TOC float on the side for easy navigation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```



```{r libs, echo=FALSE, include = FALSE}
# Input ------------------------------------

rm(list=ls()) 


source('myPaths.R')

### Libs -----------------------------------------------------------
library(lubridate)
library(dplyr)
library(sf)
library(stringr)
library(ggplot2)
library(zoo)
library(data.table)
library(ggpubr)
#library(ggpubr)   # add formulas using  stat_regline_equation(label.x=30000, label.y=40000)
library(ggpmisc)  # add equation to plots smooth 



# Colors libs 
library(RColorBrewer)
library(scales)
library(viridis)


library(tidyr)



### get data -----------------------------------
path = 'C:/Users/ge45lep/Documents/2022_BarkBeetles_Bavaria/rawData/Fwd__Borkenkäferforschung__Datentransfer'
out_path = 'C:/Users/ge45lep/Documents/2022_BarkBeetles_Bavaria'

# Load RData table
load(paste(path, 'BoMo_2015_2021_Rohdaten.RData', sep = "/"))


```

# Dataset Overview

This dataset provides information about bark beetle monitoring through the use of traps. It captures detailed attributes of each trap, its configuration, catch data, and environmental factors that may influence the results. The data is structured into multiple fields, each with specific types and purposes, as outlined below:


CRS: **EPSG:3035** (ETRS89 / LAEA Europe) is a projected coordinate system. It is:
- **Projection Type**: Lambert Azimuthal Equal-Area (LAEA).
- **Unit**: Meters.
- **Application**: Often used for statistical mapping and environmental data across Europe.


*Trap catch: Detailed information*


| Column        | Type            | Description                                                                                                                                                                                                                                   |
|---------------|-----------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| objectid      | Int             | Technical field                                                                                                                                                                                                                             |
| aelf          | Chr             | Abbreviation for the responsible forest office (Amt für Ernährung, Landwirtschaft und Forsten, AELF)                                                                                                                                       |
| kont_dat      | Date (POSIXct)  | Date the trap was emptied. There is not a given day of the week for emptying the trap, therefore the emptying interval may vary.                                                                                                             |
| falsto_name   | Chr             | Name of the trap, consists of monsto_name + trap number (1 or 2)                                                                                                                                                                            |
| art           | Chr             | Species Bark beetle (Ips typographus, Pityogenes chalcographus)                                                                                                                                                                             |
| fangmenge     | Int             | Amount of catched beetles                                                                                                                                                                                                                   |
| einheit       | Chr             | Unit – here only number of individuals (Stück). Small quantities have been counted. Large quantities have been estimated by volume: - Buchdrucker (Ips typographus) 1 ml = 40 individuals - Kupferstecher (Pityogenes chalcographus) 1 ml = 550 individuals |
| koederwechsel | Chr             | Has the bait been changed? Ja – yes; Nein - no                                                                                                                                                                                              |
| monsto_name   | Chr             | Name of the pair of trap locations. One monitoring site consists of two trap sites within two traps per bark beetle species.                                                                                                                |
| representativ | Chr             | Was the catch result representative? There are cases where a catch result is not representative: - The trap was damaged - The bait was removed. Within a radius of 200 metres: - A timber harvesting operation took place - A wood pile was laid - Infestation in the surrounding forest |
| globalid      | Chr             | ID-number of a trap location. It is possible that some trap names have more than one globalid. That is the case if the trap was relocated without renaming the monitoring location (monsto_name).                                             |


```{r, read data, echo = F, warning=F}
xy_sf <- st_read(paste(out_path, "outSpatial/all_traps_3035.gpkg", sep = '/'))
bav_sf <- st_read(paste(out_path, "outSpatial/bavaria.gpkg", sep = '/'))

# Reproject bav_sf to the CRS of xy_sf
bav_sf_repr <- st_transform(bav_sf, st_crs(xy_sf))

st_crs(xy_sf) == st_crs(bav_sf_repr)
#plot(xy_sf["falsto_name"])

# simplify: keep only one XY per trap

xy_sf_simple <- xy_sf %>%
  dplyr::select(falsto_name, geom) %>%  # Keep only falsto_name and geometry columns
  group_by(falsto_name) %>%      # Group by falsto_name
  slice(1) %>%                   # Retain only one record per group
  ungroup()                      # Ungroup the data for further operations


# Step 1: Add PairID column
xy_sf_simple <- xy_sf_simple %>%
  mutate(pairID = substr(falsto_name, 1, nchar(falsto_name) - 2))

# Step 2: Calculate average coordinates for each PairID
# Extract coordinates as separate columns
xy_sf_simple <- xy_sf_simple %>%
  mutate(x = st_coordinates(geom)[, 1],  # X coordinate
         y = st_coordinates(geom)[, 2]) # Y coordinate

# Group by PairID and calculate mean coordinates
xy_pair_avg <- xy_sf_simple %>%
  as.data.frame() %>% 
  group_by(pairID) %>%
  summarize(x = mean(x), 
            y = mean(y)) %>%
  ungroup() #%>% 
  #st_as_sf()

# Convert avg_coordinates to sf
xy_pair_sf <- xy_pair_avg %>%
  st_as_sf(coords = c("x", "y"), crs = 3035)



```

# Beetle Data Processing

The dataset includes over 73,000 records from 302 unique trap locations, capturing information on two primary beetle species (*Ips typographus* - "Buchdrucker" and *Pityogenes chalcographus* - "Kupferstecher"). 

Goal: are the trap pairs representative one to another?  Eg do we need trap pairs, or a single trap per location?

- are they correlated?
- what is difference between the two?
- how often do they cross the 3000 threshold per monitoring day?

-  compare full records
-  commpare only "representative  == TRUE"



```{r process_input_data, echo = F}
# Rename the table
dat <- Daten_B01

# Convert to date
dat$kont_dat <- as.Date(dat$kont_dat)

# Decompose date into year, month, day, and day of year
dat <- dat %>% 
  dplyr::mutate(year  = lubridate::year(kont_dat), 
                month = lubridate::month(kont_dat), 
                day   = lubridate::day(kont_dat),
                doy   = lubridate::yday(kont_dat) + 1)

# Basic statistics
#nrow(dat) # Total rows >73,000
#length(unique(dat$falsto_name)) # Total traps = 302

# Clean trap names and extract trap pair number
dat <- dat %>% 
   mutate(falsto_name = gsub(' ', '_', falsto_name)) %>% 
   mutate(falsto_name = gsub("[^A-Za-z0-9_]", "", falsto_name)) %>% 
    mutate(monsto_name = gsub("[^A-Za-z0-9_]", "", monsto_name)) %>% 
   mutate(trap_pair = as.numeric(str_extract(falsto_name, "[0-9]+")))

# Clean globalid by removing parentheses
dat <- dat %>% 
  mutate(globalid =  gsub("\\{|\\}", "", globalid))
```

*Quick data summary *

The total number of trap locations is `r length(sort(unique(xy_sf$falsto_name)))`.

Recording dates & years: 

- 2014 - does not have explicit XY information, trap data are pooled into a single globalid (XY)
- 2015:2021


In total, 138 traps has changed location 2-4 times over 2015-2021 from total of 302 locations

```{r median_days_between, echo=F}
# Get median dates between two recordings
# Calculate the number of days between recordings per 'falsto_name'
median_days_between <- dat %>%
  dplyr::filter(art == 'Buchdrucker') %>% 
  arrange(falsto_name, kont_dat) %>%  # Sort data by 'falsto_name' and 'kont_dat'
  group_by(falsto_name, year) %>%           # Group by 'falsto_name' and year
  mutate(days_diff = as.numeric(difftime(kont_dat, lag(kont_dat), units = "days"))) %>%  # Calculate days difference
  summarise(median_days = median(days_diff, na.rm = TRUE),
            mean_days = mean(days_diff, na.rm = TRUE),
            sd_days = sd(days_diff, na.rm = TRUE))  # 

# Calculate ranges for median and mean days
median_range_recording_days <- range(median_days_between$median_days, na.rm = TRUE)
mean_range_recording_days <- range(median_days_between$mean_days, na.rm = TRUE)
```




## Correlation Between Beetle counts and Year

 calculates the correlation between the number of beetles caught (`counts`) per trap pair and year, grouped by `pairID`. We used Spearmann correlation.


# Maps: over Bavaria

*Process the data:*

- split data into IPS and Pityogenes records
- remove traps pairs  that have trap_pair = 3, or A,B,C indication, instead of 1 or 2
- sum up trap counts by trapID, months - to make sure I have the correct number of records
- keep all records - indicate, if trap is problematic
- get counts per trap 1 and trap 2
- run correlations between trap 1 and trap 2



```{r clean_up_data, echo=F, warning=F}

# Select and rename the desired columns
dat_cleaned <- dat %>%
  #dplyr::filter(year !=2014) %>% 
   dplyr::filter(month %in% 4:9) %>%  # filter months during vegetation season: some has record in januay, march ..
  dplyr::select(
    year,
    doy,
    #month,
    fangmenge,
    art,
    falsto_name,
    monsto_name,
    trap_pair
  ) %>%
  dplyr::rename(
    count = fangmenge,
    species = art,
    trapID = falsto_name,
    pairID = monsto_name
  )

# Display the first few rows of the cleaned dataset
#head(dat_cleaned)
print(summary(dat_cleaned))

# sum ups counts per month to ryun correlations
dat_cleaned_sum_month <-  dat_cleaned %>% 
  group_by(pairID, trapID, species, year, doy, trap_pair) %>%
  dplyr::summarise(
    count = sum(count, na.rm = TRUE),
    .groups = "drop"
  ) %>% 
  dplyr::filter(trap_pair != 3) %>% 
  ungroup(.)

```
# Results

## IPS

```{r ips_correlation, include = F, warning = F, echo = F}

# Split the data into two datasets by species
ips_data <- dat_cleaned %>% #dat_cleaned_sum_month %>%
  dplyr::filter(species == "Buchdrucker") %>% 
  ungroup(.)

# Reshape data into wide format with counts from trap_pair 1 and 2
ips_wide <- ips_data %>%
  group_by(pairID, species, year, doy) %>% # Group by necessary columns
  summarise(count_1 = sum(count[trap_pair == 1], na.rm = TRUE),  # Sum counts for trap_pair 1
            count_2 = sum(count[trap_pair == 2], na.rm = TRUE),  # Sum counts for trap_pair 2
            #count_3 = sum(count[trap_pair == 3], na.rm = TRUE),  # Sum counts for trap_pair 3 (if applicable)
            .groups = "drop") %>% # Ungroup the data after summarising
  mutate(over_3k = case_when(
    count_1 > 3000 & count_2 > 3000 ~ 'over',       # Both counts > 3000
    count_1 > 3000 | count_2 > 3000 ~ 'no_fit',    # Only one count > 3000
    count_1 <= 3000 & count_2 <= 3000 ~ 'less'     # Both counts <= 3000
  ))


# Calculate percentages of each class in `over_3k`
ips_3k_percentages <- ips_wide %>%
  group_by(pairID, year, over_3k) %>%  # Group by pairID, year, and over_3k
  summarize(class_count = n(), .groups = "drop") %>%  # Count occurrences of each class
  group_by(pairID, year) %>%  # Group again by pairID and year
  mutate(class_percentage = class_count / sum(class_count) * 100) %>%  # Calculate percentages
  ungroup()

# keep only higher from teh classes: over and no_fit, remve 'less'
ips_3k_percentages_sub <- ips_3k_percentages %>% 
  dplyr::filter(over_3k != 'less') %>% 
  group_by(pairID, year) %>%
  slice_max(class_percentage, with_ties = FALSE) %>%
  ungroup() %>% 
  dplyr::select(-class_count)



correlations_ips <- ips_wide %>%
  group_by(pairID, year) %>% # Group by pairID and year
  summarize(
    spearm_cor = cor(count_1, count_2, use = "pairwise.complete.obs", method = "spearman"), # Calculate correlation
    record_count = n(), # Count the number of records in each group
    mean_counts = mean(c(count_1, count_2), na.rm = TRUE),           # Mean of counts
    sd_counts = sd(c(count_1, count_2), na.rm = TRUE),               # Standard deviation of counts
    cv_counts = sd_counts / mean_counts * 100                        # Coefficient of Variation (%)
  ) %>%
 
  ungroup()

correlations_ips <- correlations_ips %>%
  left_join(ips_3k_percentages_sub)

# add to original table
# correlations_ips <- correlations_ips %>%
#   left_join(ips_class_percentages %>% 
#               select(pairID, year, over_3k, class_percentage),
#             by = c("pairID", "year"))

# merge datao to plot them on teh map
corr_year <- xy_pair_sf %>% 
  inner_join(correlations_ips, by = join_by(pairID))


```

# Maps

Distribution of the Spearman correlation 

```{r ips_cor_map, include = T, warning = F, echo = F}

# Create the plot
ggplot() +
  geom_sf(data = bav_sf_repr, fill = 'grey', color = 'black') +  # Add the bav_sf_repr layer as grey
  geom_sf(data = corr_year, aes(color = spearm_cor), size = 2) +  # Plot points with color representing Spearman correlationSpearman correlation
  #scale_color_viridis_c(option = "plasma", name = "Spearman\nCorrelation") +  # Use a continuous color scale
   scale_color_gradient2(
    low = "blue",     # Color for low values
    mid = "white",    # Color for 0 values
    high = "red",     # Color for high values
    midpoint = 0,     # The point where 'white' is assigned
    #limits = c(-0.25, 9),  # Scale limits
    name = "Spearman\nCorrelation"  # Legend title
  ) +
  facet_wrap(~ year) +  # Facet the plot by year
  theme_void() +  # Minimal theme for better aesthetics
  labs(
    title = "Spatial Distribution of Spearman Correlation by Year",
    x = "Longitude",
    y = "Latitude"
  )

```
Distribution of the coefficient of variation 


```{r ips_cv_map, include = T, warning = F, echo = F}

# Create the plot
ggplot() +
  geom_sf(data = bav_sf_repr, fill = 'grey', color = 'black') +  # Add the bav_sf_repr layer as grey
  geom_sf(data = corr_year, aes(color = cv_counts), size = 2) +  # Plot points with color representing Spearman correlationSpearman correlation
  #scale_color_viridis_c(option = "plasma", name = "Coefficient of variation") +  # Use a continuous color scale
  scale_color_viridis_c(
    option = "plasma",
    name = "Coefficient of variation\n(capped at 150)",
    limits = c(0, 150),  # Set limits
    oob = scales::squish  # Values above 200 squish to max (200)
  ) +
   facet_wrap(~ year) +  # Facet the plot by year
  
  theme_void() +  # Minimal theme for better aesthetics
  labs(
    title = "Spatial Distribution of Coefficient of variation by Year",
    x = "Longitude",
    y = "Latitude"
  )

```

Distribution of the Outbreak indicator fit




```{r ips_3k_map, include = T, warning = F, echo = F}

# Create the plot
ggplot() +
  geom_sf(data = bav_sf_repr, fill = 'grey', color = 'black') +  # Add the bav_sf_repr layer as grey
  geom_sf(data = corr_year, aes(color = over_3k ), size = 2) +  # Plot points with color representing Spearman correlationSpearman correlation
  scale_color_viridis_d(option = "plasma", name = "Outbreak indicator fit") +  # Use a continuous color scale
   facet_wrap(~ year) +  # Facet the plot by year
  theme_void() +  # Minimal theme for better aesthetics
  labs(
    title = "Spatial Distribution of Oubreak indicator fit by Year",
    x = "Longitude",
    y = "Latitude"
  )

```




```{r ips_summary_old}

# # Summarize correlation values per year
correlation_ips_summary <- correlations_ips %>%
  group_by(year) %>%
  summarise(
    mean_correlation = mean(spearm_cor, na.rm = TRUE),  # Mean correlation
    sd_correlation = sd(spearm_cor, na.rm = TRUE),      # Standard deviation
    median_correlation = median(spearm_cor, na.rm = TRUE),  # Median correlation
    iqr_correlation = IQR(spearm_cor, na.rm = TRUE),    # Interquartile range
    .groups = "drop"
  )

# Calculate the 5th percentile of correlations
correlation_5th_percentile_ips <- quantile(correlations_ips$spearm_cor, probs = 0.05, na.rm = TRUE)

# Filter rows with correlations below or equal to the 5th percentile
lowest_correlations_ips <- correlations_ips %>%
  dplyr::filter(spearm_cor <= correlation_5th_percentile_ips) %>%
  dplyr::arrange(spearm_cor)


```





```{r make_plots}

# correlations_ips %>% 
#   ggplot(aes(x = year, y = cv_counts)) + 
#   geom_jitter(alpha = 0.5) + 
#   geom_smooth()
# 
# 
# 
# correlations_ips %>% 
#   ggplot(aes(x = year, y = correlation)) + 
#   geom_jitter(alpha = 0.5) + 
#   geom_smooth()

# 
# correlations_ips %>% 
#   dplyr::filter(correlation > 0) %>% 
#   ggplot(aes(x = correlation, y = cv_counts)) + 
#   geom_jitter(alpha = 0.5) + 
#   geom_smooth()



```



Density distribution of correlations between traps, grouped by trapID.

```{r corr_density, echo  = F,warning = F, fig.cap="Density Distribution of Correlations by Year"}
# Create the density plot with vertical lines for mean and median
p_dens_ips <- ggplot(correlations_ips, aes(x = spearm_cor, fill = as.factor(year))) +
  geom_density(alpha = 0.5) +  # Density plot with transparency
  facet_wrap(~ year, scales = "free_y") +  # Facet by year for separate density plots
  geom_vline(
    data = correlation_ips_summary,
    aes(xintercept = mean_correlation, color = "Mean"),
    linetype = "dashed",
    linewidth = 0.8
  ) +  # Add vertical lines for mean
  geom_vline(
    data = correlation_ips_summary,
    aes(xintercept = median_correlation, color = "Median"),
    linetype = "dotted",
    linewidth = 0.8
  ) +  # Add vertical lines for median
  labs(
    title = "Ips",
    x = "Correlation",
    y = "Density",
    fill = "Year",
    color = "Statistics"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")


```


### How often have traps high correlation?


```{r corr_text, echo = F, warning=FALSE}
# Cut data into correlation classes
correlations_ips <- correlations_ips %>%
 mutate(correlation_class = case_when(
    is.na(spearm_cor) ~ "NA",   
    spearm_cor >= 0.90 ~ ">90",                      # Strictly greater than 0.90
    spearm_cor > 0.75 & spearm_cor <= 0.90 ~ "75-90",  # Greater than 0.75 and up to 0.90
    spearm_cor >= 0 & spearm_cor <= 0.75 ~ "0-75",     # From 0 to 0.75 (inclusive)
    spearm_cor < 0 ~ "<0"                           # Strictly less than 0
))

# Calculate the total number of records per year
total_records_per_year <- correlations_ips %>%
  group_by(year) %>%
  summarise(total_records = n(), .groups = "drop")

# Count the number of records in each correlation class per year
correlation_ips_share <- correlations_ips %>%
  group_by(year, correlation_class) %>%
  summarise(record_count = n(), .groups = "drop") %>%
  left_join(total_records_per_year, by = "year") %>%
  mutate(percentage = (record_count / total_records) * 100)
```



```{r ips_barplot, echo = F, warning=F, fig.cap = 'Share of traps pairs with correlation > 90 over years'}

# Filter only the class ">90"
p_corr_share_ips <- correlation_ips_share %>%
  dplyr::filter(correlation_class == ">90") %>% 
  ggplot(aes(x = factor(year), y = percentage)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(
    title = "Ips",
    x = "Year",
    y = "Percentage (%)"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

Trap pairs with correlations lower then 5-percentil:


```{r corr_total_records, echo = T, warning=F}

# Calculate total number of records
total_records_ips <- nrow(correlations_ips)

# Count records with less than 6 per year
less_than_6_ips <- correlations_ips %>%
  filter(record_count < 6) %>%
  summarise(
    count = n(),                              # Count of records with < 6
    percentage = (n() / total_records_ips) * 100  # Percentage of total records
  )
# Display results
print(less_than_6_ips)


# Filter the data to keep only unique pairID and year combinations with insufficient records
insufficient_records_ips <- correlations_ips  %>%
  dplyr::filter(record_count  < 6) %>%       # Ensure the condition for "not enough records"
  dplyr::select(pairID, year) %>%    # Select only pairID and year columns
  distinct()                  # Keep unique combinations

# Display the results
print(insufficient_records_ips)

```


## Pityogenes

```{r pityogenes_correlation, include = F, warning = F, echo = F}

# Split the data into two datasets by species
pityogenes_data <- dat_cleaned %>%
  dplyr::filter(species == "Kupferstecher") %>% 
  ungroup()

# Reshape data into wide format with counts from trap_pair 1 and 2
pityogenes_wide <- pityogenes_data %>%
  group_by(pairID, species, year, doy) %>% # Group by necessary columns
  summarise(count_1 = sum(count[trap_pair == 1], na.rm = TRUE),  # Sum counts for trap_pair 1
            count_2 = sum(count[trap_pair == 2], na.rm = TRUE),  # Sum counts for trap_pair 2
            count_3 = sum(count[trap_pair == 3], na.rm = TRUE),  # Sum counts for trap_pair 3 (if applicable)
            .groups = "drop") # Ungroup the data after summarising


correlations_pityogenes <- pityogenes_wide %>%
  group_by(pairID, year) %>% # Group by pairID and year
  mutate(
    spearm_cor = cor(count_1, count_2, use = "pairwise.complete.obs", method = "spearman"), # Calculate correlation
    record_count = n(), # Count the number of records in each group
    .groups = "drop"
  ) 

# Summarize correlation values per year
correlation_pity_summary <- correlations_pityogenes %>%
  group_by(year) %>%
  summarise(
    mean_correlation    = mean(spearm_cor, na.rm = TRUE),  # Mean correlation
    sd_correlation      = sd(spearm_cor, na.rm = TRUE),      # Standard deviation
    median_correlation  = median(spearm_cor, na.rm = TRUE),  # Median correlation
    iqr_correlation     = IQR(spearm_cor, na.rm = TRUE),    # Interquartile range
    .groups = "drop"
  )

# Calculate the 5th percentile of correlations
correlation_5th_percentile_pityogenes <- quantile(correlations_pityogenes$spearm_cor, probs = 0.05, na.rm = TRUE)

# Filter rows with correlations below or equal to the 5th percentile
lowest_correlations_pityogenes <- correlations_pityogenes %>%
  dplyr::filter(spearm_cor <= correlation_5th_percentile_pityogenes) %>% 
  dplyr::arrange(spearm_cor)

```

Density distribution


```{r get_pity_barplot, echo = F, warning=FALSE}
# Cut data into correlation classes
correlations_pityogenes <- correlations_pityogenes %>%
 mutate(correlation_class = case_when(
    is.na(spearm_cor) ~ "NA",   
    spearm_cor >= 0.90 ~ ">90",                      # Strictly greater than 0.90
    spearm_cor > 0.75 & spearm_cor <= 0.90 ~ "75-90",  # Greater than 0.75 and up to 0.90
    spearm_cor >= 0 & spearm_cor <= 0.75 ~ "0-75",     # From 0 to 0.75 (inclusive)
    spearm_cor < 0 ~ "<0"                           # Strictly less than 0
))

# Calculate the total number of records per year
total_records_per_year_pityogenes <- correlations_pityogenes %>%
  group_by(year) %>%
  summarise(total_records = n(), .groups = "drop")

# Count the number of records in each correlation class per year
correlation_pity_share <- correlations_pityogenes %>%
  group_by(year, correlation_class) %>%
  summarise(record_count = n(), .groups = "drop") %>%
  left_join(total_records_per_year_pityogenes, by = "year") %>%
  mutate(percentage = (record_count / total_records) * 100)

```

```{r corr_density_pityogenes, echo = F, warning = F, fig.cap="Density Distribution of Correlations for Kupferstecher by Year"}
# Create the density plot with vertical lines for mean and median
p_dens_pity <- ggplot(correlations_pityogenes, aes(x = spearm_cor, fill = as.factor(year))) +
  geom_density(alpha = 0.5) +  # Density plot with transparency
  facet_wrap(~ year, scales = "free_y") +  # Facet by year for separate density plots
  geom_vline(
    data = correlation_pity_summary,
    aes(xintercept = mean_correlation, color = "Mean"),
    linetype = "dashed",
    linewidth = 0.8
  ) +  # Add vertical lines for mean
  geom_vline(
    data = correlation_pity_summary,
    aes(xintercept = median_correlation, color = "Median"),
    linetype = "dotted",
    linewidth = 0.8
  ) +  # Add vertical lines for median
  labs(
    title = "Pityogenes",
    x = "Correlation",
    y = "Density",
    fill = "Year",
    color = "Statistics"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
```




```{r pity_barplot, echo = F, warning=F, fig.cap = 'Share of traps pairs with correlation > 90 over years'}

# Filter only the class ">90"
p_corr_share_pity <- correlation_pity_share %>%
  dplyr::filter(correlation_class == ">90") %>% 
  ggplot(aes(x = factor(year), y = percentage)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(
    title = "Pityogenes",
    x = "Year",
    y = "Percentage (%)"
  ) +
  theme_minimal() +
  ylim(0,60) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```


# Correlations between traps

```{r p_dens, fig.cap = "Ensity distribution of correlations over years"}

ggarrange(p_dens_ips , p_dens_pity  , common.legend = T)
```



```{r p_corr_share, fig.cap = "Share of trap pairs with high correlation over years"}

ggarrange(p_corr_share_ips, p_corr_share_pity  )
```








