---
title: "Beetle Data LWF Report"
author: "Maria Potterf"
date: "2024-12-13"
output: 
  html_document:
    toc: true           # Adds a table of contents
    toc_depth: 3        # Limits TOC to headings level 1 and 2
    number_sections: true  # Adds numbering to the headings
    toc_float: true     # Makes the TOC float on the side for easy navigation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```



```{r libs, echo=FALSE, include = FALSE}
# Input ------------------------------------

rm(list=ls()) 


source('myPaths.R')

### Libs -----------------------------------------------------------
library(lubridate)
library(dplyr)
library(sf)
library(stringr)
library(ggplot2)
library(zoo)
library(data.table)
library(ggpubr)
#library(ggpubr)   # add formulas using  stat_regline_equation(label.x=30000, label.y=40000)
library(ggpmisc)  # add equation to plots smooth 



# Colors libs 
library(RColorBrewer)
library(scales)
library(viridis)


library(tidyr)



### get data -----------------------------------
path = 'C:/Users/ge45lep/Documents/2022_BarkBeetles_Bavaria/rawData/Fwd__Borkenkäferforschung__Datentransfer'
out_path = 'C:/Users/ge45lep/Documents/2022_BarkBeetles_Bavaria'

# Load RData table
load(paste(path, 'BoMo_2015_2021_Rohdaten.RData', sep = "/"))


```

# Dataset Overview

This dataset provides information about bark beetle monitoring through the use of traps. It captures detailed attributes of each trap, its configuration, catch data, and environmental factors that may influence the results. The data is structured into multiple fields, each with specific types and purposes, as outlined below:

## Technical and Identification Fields:
- **objectid**: An integer field serving as a technical identifier for each record.
- **globalid**: A character field that uniquely identifies a trap location. Some traps may have multiple `globalid` values due to relocations without renaming.

## Trap and Monitoring Information:
- **aelf**: Abbreviation for the responsible forest office (Amt für Ernährung, Landwirtschaft und Forsten, AELF).
- **monsto_name**: The name of the monitoring site, representing pairs of trap locations.
- **falsto_name**: The name of the specific trap, composed of `monsto_name` and the trap number.

## Catch Data:
- **art**: The species of bark beetle (e.g., *Ips typographus* or *Pityogenes chalcographus*).
- **fangmenge**: The number of beetles caught in a trap.
- **einheit**: The unit of measurement for the catch (typically the number of individuals). Small quantities are directly counted, while large quantities are estimated based on volume:
  - *Ips typographus*: 1 mL = 40 individuals.
  - *Pityogenes chalcographus*: 1 mL = 550 individuals.

## Monitoring Details:
- **kont_dat**: The date the trap was emptied (POSIXct format). The emptying intervals may vary as no fixed day is set.
- **koederwechsel**: Indicates whether the bait in the trap was changed (`Ja` for yes, `Nein` for no).
- **representativ**: Notes if the catch result is representative. Results may be non-representative if:
  - The trap was damaged.
  - The bait was removed.
  - Significant environmental disturbances occurred, such as timber harvesting, wood piling, or infestations in the surrounding forest within a 200-meter radius.

This dataset is crucial for monitoring bark beetle populations and analyzing environmental impacts on catch rates, providing insights into forest health and pest management practices.

### CRS: **EPSG:3035** (ETRS89 / LAEA Europe) is a projected coordinate system. It is:
- **Projection Type**: Lambert Azimuthal Equal-Area (LAEA).
- **Unit**: Meters.
- **Application**: Often used for statistical mapping and environmental data across Europe.


### Trap catch: Detailed information


| Column        | Type            | Description                                                                                                                                                                                                                                   |
|---------------|-----------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| objectid      | Int             | Technical field                                                                                                                                                                                                                             |
| aelf          | Chr             | Abbreviation for the responsible forest office (Amt für Ernährung, Landwirtschaft und Forsten, AELF)                                                                                                                                       |
| kont_dat      | Date (POSIXct)  | Date the trap was emptied. There is not a given day of the week for emptying the trap, therefore the emptying interval may vary.                                                                                                             |
| falsto_name   | Chr             | Name of the trap, consists of monsto_name + trap number (1 or 2)                                                                                                                                                                            |
| art           | Chr             | Species Bark beetle (Ips typographus, Pityogenes chalcographus)                                                                                                                                                                             |
| fangmenge     | Int             | Amount of catched beetles                                                                                                                                                                                                                   |
| einheit       | Chr             | Unit – here only number of individuals (Stück). Small quantities have been counted. Large quantities have been estimated by volume: - Buchdrucker (Ips typographus) 1 ml = 40 individuals - Kupferstecher (Pityogenes chalcographus) 1 ml = 550 individuals |
| koederwechsel | Chr             | Has the bait been changed? Ja – yes; Nein - no                                                                                                                                                                                              |
| monsto_name   | Chr             | Name of the pair of trap locations. One monitoring site consists of two trap sites within two traps per bark beetle species.                                                                                                                |
| representativ | Chr             | Was the catch result representative? There are cases where a catch result is not representative: - The trap was damaged - The bait was removed. Within a radius of 200 metres: - A timber harvesting operation took place - A wood pile was laid - Infestation in the surrounding forest |
| globalid      | Chr             | ID-number of a trap location. It is possible that some trap names have more than one globalid. That is the case if the trap was relocated without renaming the monitoring location (monsto_name).                                             |


```{r, read data}
xy_sf <- st_read(paste(out_path, "outSpatial/all_traps_3035.gpkg", sep = '/'))

plot(xy_sf["falsto_name"])
```

# Beetle Data Processing

This section processes beetle trap data for analysis. The dataset includes over 73,000 records from 302 unique trap locations, capturing information on two primary beetle species (*Ips typographus* - "Buchdrucker" and *Pityogenes chalcographus* - "Kupferstecher"). The data is prepared for further spatial and temporal analyses by cleaning, transforming, and adding key attributes. Below is the detailed breakdown of the processing steps:

## Key Steps:
1. **Data Preparation**:
   - The original data table (`Daten_B01`) is renamed to `dat`.
   - The trap emptying dates (`kont_dat`) are converted to the `Date` format.

2. **Date Decomposition**:
   - The `kont_dat` field is split into `year`, `month`, `day`, and `day of year (doy)` to analyze temporal variations.

3. **Basic Data Insights**:
   - The dataset contains over 73,000 rows and 302 unique trap locations (`falsto_name`).

4. **Data Cleaning**:
   - Spaces and special characters in `falsto_name` are replaced with underscores or removed.
   - A new field `trap_pair` is extracted to represent trap pair numbers.
   - The `globalid` field is cleaned by removing parentheses for better merging with spatial data.

5. **Output**:
   - The cleaned and transformed dataset (`dat`) is ready for merging with spatial data and further analysis.

```{r process_input_data, echo = F}
# Rename the table
dat <- Daten_B01

# Convert to date
dat$kont_dat <- as.Date(dat$kont_dat)

# Decompose date into year, month, day, and day of year
dat <- dat %>% 
  dplyr::mutate(year  = lubridate::year(kont_dat), 
                month = lubridate::month(kont_dat), 
                day   = lubridate::day(kont_dat),
                doy   = lubridate::yday(kont_dat) + 1)

# Basic statistics
nrow(dat) # Total rows >73,000
length(unique(dat$falsto_name)) # Total traps = 302

# Clean trap names and extract trap pair number
dat <- dat %>% 
   mutate(falsto_name = gsub(' ', '_', falsto_name)) %>% 
   mutate(falsto_name = gsub("[^A-Za-z0-9_]", "", falsto_name)) %>% 
    mutate(monsto_name = gsub("[^A-Za-z0-9_]", "", monsto_name)) %>% 
   mutate(trap_pair = as.numeric(str_extract(falsto_name, "[0-9]+")))

# Clean globalid by removing parentheses
dat <- dat %>% 
  mutate(globalid =  gsub("\\{|\\}", "", globalid))
```

### Overview 

The total number of trap locations is `r length(sort(unique(xy_sf$falsto_name)))`.

Recording dates & years: 

- 2014 - does not have explicit XY information, trap data are pooled into a single globalid (XY)
- 2015:2021


In total, 138 traps has changed location 2-40 times over 2015-2021 from total of 302 locations

## Median Days Between Recordings
```{r median_days_between, echo=F}
# Get median dates between two recordings
# Calculate the number of days between recordings per 'falsto_name'
median_days_between <- dat %>%
  dplyr::filter(art == 'Buchdrucker') %>% 
  arrange(falsto_name, kont_dat) %>%  # Sort data by 'falsto_name' and 'kont_dat'
  group_by(falsto_name, year) %>%           # Group by 'falsto_name' and year
  mutate(days_diff = as.numeric(difftime(kont_dat, lag(kont_dat), units = "days"))) %>%  # Calculate days difference
  summarise(median_days = median(days_diff, na.rm = TRUE),
            mean_days = mean(days_diff, na.rm = TRUE),
            sd_days = sd(days_diff, na.rm = TRUE))  # 

# Calculate ranges for median and mean days
median_range_recording_days <- range(median_days_between$median_days, na.rm = TRUE)
mean_range_recording_days <- range(median_days_between$mean_days, na.rm = TRUE)
```

The range for the **median days** was (`r median_range_recording_days[1]` to `r median_range_recording_days[2]`), 
and for the **mean days**, it was (`r round(mean_range_recording_days[1],0)` to `r round(mean_range_recording_days[2],0)`).


## Correlation Between Beetle counts and Year

The following analysis calculates the correlation between the number of beetles caught (`counts`) and the year of data collection, grouped by `pairID` and beetle species. This allows us to see how correlations between traps within trap pairs change change over time for each monitoring site. We used Spearman correlation.


```{r clean_up_data, echo=F}

# Select and rename the desired columns
dat_cleaned <- dat %>%
  dplyr::filter(year !=2014) %>% 
   dplyr::filter(month %in% 4:9) %>%  # filter months during vegetation season: some has record in januay, march ..
  dplyr::select(
    year,
    month,
    fangmenge,
    art,
    falsto_name,
    monsto_name,
    trap_pair
  ) %>%
  dplyr::rename(
    count = fangmenge,
    species = art,
    trapID = falsto_name,
    pairID = monsto_name
  )

# Display the first few rows of the cleaned dataset
#head(dat_cleaned)
print(summary(dat_cleaned))

# sum ups counts per month to ryun correlations
dat_cleaned_sum_month <-  dat_cleaned %>% 
  group_by(pairID, trapID, species, year, month, trap_pair) %>%
  dplyr::summarise(
    count = sum(count, na.rm = TRUE),
    .groups = "drop"
  ) %>% 
  dplyr::filter(trap_pair != 3) %>% 
  ungroup(.)

```
Sites with very few recording times per year: if revisit is every 2 weeks, each trap should have 7*2 records (at least) = 14 records/year

Process the data:
- split data into IPS and Pityogenes records
- remove traps pairs  that have trap_pair = 3, or A,B,C indication, instead of 1 or 2
- sum up trap counts by trapID, months - to make sure I have the correct number of records
- remove if there is < 7 records per year & trapID
- get counts per trap 1 and trap 2
- run correlations between trap 1 and trap 2

## IPS

```{r ips_correlation, include = F, warning = F, echo = F}

# Split the data into two datasets by species
ips_data <- dat_cleaned %>% #dat_cleaned_sum_month %>%
  dplyr::filter(species == "Buchdrucker") %>% 
  ungroup(.)

# Reshape data into wide format with counts from trap_pair 1 and 2
ips_wide <- ips_data %>%
  group_by(pairID, species, year, month) %>% # Group by necessary columns
  summarise(count_1 = sum(count[trap_pair == 1], na.rm = TRUE),  # Sum counts for trap_pair 1
            count_2 = sum(count[trap_pair == 2], na.rm = TRUE),  # Sum counts for trap_pair 2
            count_3 = sum(count[trap_pair == 3], na.rm = TRUE),  # Sum counts for trap_pair 3 (if applicable)
            .groups = "drop") # Ungroup the data after summarising


correlations_ips <- ips_wide %>%
  group_by(pairID, year) %>% # Group by pairID and year
  mutate(
    correlation = cor(count_1, count_2, use = "pairwise.complete.obs", method = "spearman"), # Calculate correlation
    record_count = n(), # Count the number of records in each group
    .groups = "drop"
  ) 

# !!! how many sites has very less records???


# Summarize correlation values per year
correlation_ips_summary <- correlations_ips %>%
  group_by(year) %>%
  summarise(
    mean_correlation = mean(correlation, na.rm = TRUE),  # Mean correlation
    sd_correlation = sd(correlation, na.rm = TRUE),      # Standard deviation
    median_correlation = median(correlation, na.rm = TRUE),  # Median correlation
    iqr_correlation = IQR(correlation, na.rm = TRUE),    # Interquartile range
    .groups = "drop"
  )

# Calculate the 5th percentile of correlations
correlation_5th_percentile_ips <- quantile(correlations_ips$correlation, probs = 0.05, na.rm = TRUE)

# Filter rows with correlations below or equal to the 5th percentile
lowest_correlations_ips <- correlations_ips %>%
  dplyr::filter(correlation <= correlation_5th_percentile_ips) %>% 
  dplyr::arrange(correlation)


```

Density distribution of correlations between traps, groupped by trapID.

```{r corr_density, echo  = F,warning = F, fig.cap="Density Distribution of Correlations by Year"}
# Create the density plot with vertical lines for mean and median
p_dens_ips <- ggplot(correlations_ips, aes(x = correlation, fill = as.factor(year))) +
  geom_density(alpha = 0.5) +  # Density plot with transparency
  facet_wrap(~ year, scales = "free_y") +  # Facet by year for separate density plots
  geom_vline(
    data = correlation_ips_summary,
    aes(xintercept = mean_correlation, color = "Mean"),
    linetype = "dashed",
    linewidth = 0.8
  ) +  # Add vertical lines for mean
  geom_vline(
    data = correlation_ips_summary,
    aes(xintercept = median_correlation, color = "Median"),
    linetype = "dotted",
    linewidth = 0.8
  ) +  # Add vertical lines for median
  labs(
    title = "Ips",
    x = "Correlation",
    y = "Density",
    fill = "Year",
    color = "Statistics"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")


```


### How often have traps high correlation?


```{r corr_text, echo = F, warning=FALSE}
# Cut data into correlation classes
correlations_ips <- correlations_ips %>%
 mutate(correlation_class = case_when(
    is.na(correlation) ~ "NA",   
    correlation >= 0.90 ~ ">90",                      # Strictly greater than 0.90
    correlation > 0.75 & correlation <= 0.90 ~ "75-90",  # Greater than 0.75 and up to 0.90
    correlation >= 0 & correlation <= 0.75 ~ "0-75",     # From 0 to 0.75 (inclusive)
    correlation < 0 ~ "<0"                           # Strictly less than 0
))

# Calculate the total number of records per year
total_records_per_year <- correlations_ips %>%
  group_by(year) %>%
  summarise(total_records = n(), .groups = "drop")

# Count the number of records in each correlation class per year
correlation_ips_summary <- correlations_ips %>%
  group_by(year, correlation_class) %>%
  summarise(record_count = n(), .groups = "drop") %>%
  left_join(total_records_per_year, by = "year") %>%
  mutate(percentage = (record_count / total_records) * 100)
```



```{r ips_barplot, echo = F, warning=F, fig.cap = 'Share of traps pairs with correlation > 90 over years'}

# Filter only the class ">90"
p_corr_share_ips <- correlation_ips_summary %>%
  dplyr::filter(correlation_class == ">90") %>% 
  ggplot(aes(x = factor(year), y = percentage)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(
    title = "Ips",
    x = "Year",
    y = "Percentage (%)"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

Trap pairs with correlations lower then 5-percentil:


```{r corr_total_records, echo = T, warning=F}

# Calculate total number of records
total_records_ips <- nrow(correlations_ips)

# Count records with less than 6 per year
less_than_6_ips <- correlations_ips %>%
  filter(record_count < 6) %>%
  summarise(
    count = n(),                              # Count of records with < 6
    percentage = (n() / total_records_ips) * 100  # Percentage of total records
  )
# Display results
print(less_than_6_ips)


# Filter the data to keep only unique pairID and year combinations with insufficient records
insufficient_records_ips <- less_than_6_ips %>%
  dplyr::filter(count < 6) %>%       # Ensure the condition for "not enough records"
  dplyr::select(pairID, year) %>%    # Select only pairID and year columns
  distinct()                  # Keep unique combinations

# Display the results
print(insufficient_records_ips)

```


## Pityogenes

```{r pityogenes_correlation, include = F, warning = F, echo = F}

# Split the data into two datasets by species
pityogenes_data <- dat_cleaned %>%
  dplyr::filter(species == "Kupferstecher") %>% 
  ungroup()

# Reshape data into wide format with counts from trap_pair 1 and 2
pityogenes_wide <- pityogenes_data %>%
  group_by(pairID, species, year, month) %>% # Group by necessary columns
  summarise(count_1 = sum(count[trap_pair == 1], na.rm = TRUE),  # Sum counts for trap_pair 1
            count_2 = sum(count[trap_pair == 2], na.rm = TRUE),  # Sum counts for trap_pair 2
            count_3 = sum(count[trap_pair == 3], na.rm = TRUE),  # Sum counts for trap_pair 3 (if applicable)
            .groups = "drop") # Ungroup the data after summarising


correlations_pityogenes <- pityogenes_wide %>%
  group_by(pairID, year) %>% # Group by pairID and year
  mutate(
    correlation = cor(count_1, count_2, use = "pairwise.complete.obs", method = "spearman"), # Calculate correlation
    record_count = n(), # Count the number of records in each group
    .groups = "drop"
  ) 

# Summarize correlation values per year
correlation_pity_summary <- correlations_pityogenes %>%
  group_by(year) %>%
  summarise(
    mean_correlation = mean(correlation, na.rm = TRUE),  # Mean correlation
    sd_correlation = sd(correlation, na.rm = TRUE),      # Standard deviation
    median_correlation = median(correlation, na.rm = TRUE),  # Median correlation
    iqr_correlation = IQR(correlation, na.rm = TRUE),    # Interquartile range
    .groups = "drop"
  )

# Calculate the 5th percentile of correlations
correlation_5th_percentile_pityogenes <- quantile(correlations_pityogenes$correlation, probs = 0.05, na.rm = TRUE)

# Filter rows with correlations below or equal to the 5th percentile
lowest_correlations_pityogenes <- correlations_pityogenes %>%
  dplyr::filter(correlation <= correlation_5th_percentile_pityogenes) %>% 
  dplyr::arrange(correlation)

```

Density distribution

```{r corr_density_pityogenes, echo = F, warning = F, fig.cap="Density Distribution of Correlations for Kupferstecher by Year"}
# Create the density plot with vertical lines for mean and median
p_dens_pity <- ggplot(correlations_pityogenes, aes(x = correlation, fill = as.factor(year))) +
  geom_density(alpha = 0.5) +  # Density plot with transparency
  facet_wrap(~ year, scales = "free_y") +  # Facet by year for separate density plots
  geom_vline(
    data = correlation_pity_summary,
    aes(xintercept = mean_correlation, color = "Mean"),
    linetype = "dashed",
    linewidth = 0.8
  ) +  # Add vertical lines for mean
  geom_vline(
    data = correlation_pity_summary,
    aes(xintercept = median_correlation, color = "Median"),
    linetype = "dotted",
    linewidth = 0.8
  ) +  # Add vertical lines for median
  labs(
    title = "Pityogenes",
    x = "Correlation",
    y = "Density",
    fill = "Year",
    color = "Statistics"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
```

```{r get_pity_barplot, echo = F, warning=FALSE}
# Cut data into correlation classes
correlations_pityogenes <- correlations_pityogenes %>%
 mutate(correlation_class = case_when(
    is.na(correlation) ~ "NA",   
    correlation >= 0.90 ~ ">90",                      # Strictly greater than 0.90
    correlation > 0.75 & correlation <= 0.90 ~ "75-90",  # Greater than 0.75 and up to 0.90
    correlation >= 0 & correlation <= 0.75 ~ "0-75",     # From 0 to 0.75 (inclusive)
    correlation < 0 ~ "<0"                           # Strictly less than 0
))

# Calculate the total number of records per year
total_records_per_year_pityogenes <- correlations_pityogenes %>%
  group_by(year) %>%
  summarise(total_records = n(), .groups = "drop")

# Count the number of records in each correlation class per year
correlation_pity_summary <- correlations_pityogenes %>%
  group_by(year, correlation_class) %>%
  summarise(record_count = n(), .groups = "drop") %>%
  left_join(total_records_per_year_pityogenes, by = "year") %>%
  mutate(percentage = (record_count / total_records) * 100)

```


```{r pity_barplot, echo = F, warning=F, fig.cap = 'Share of traps pairs with correlation > 90 over years'}

# Filter only the class ">90"
p_corr_share_pity <- correlation_pity_summary %>%
  dplyr::filter(correlation_class == ">90") %>% 
  ggplot(aes(x = factor(year), y = percentage)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(
    title = "Pityogenes",
    x = "Year",
    y = "Percentage (%)"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```


# Correlations between traps

```{r p_dens, fig.cap = "Ensity distribution of correlations over years"}

ggarrange(p_dens_ips , p_dens_pity  , common.legend = T)
```



```{r p_corr_share, fig.cap = "Share of trap pairs with high correlation over years"}

ggarrange(p_corr_share_ips, p_corr_share_pity  )
```








